model:
  # model 관련
  d_model: 128 # 논문 : 512
  nhead: 8
  num_encoder_layers: 3 # 논문 6
  num_decoder_layers: 3 # 논문 6
  dim_feedforward: 1024 # 논문1024
  dropout: 0.1

  training: True
  save_period: 10
  load_period: 210

hyperparameters:
  # 학습 관련
  epoch: 210
  batch_size: 4
  batch_log: 100
  subdivision: 1
  pin_memory: True
  num_workers: 8 # the number of multiprocessing workers to use for data preprocessing.
  optimizer: ADAM # ADAM, RMSPROP
  learning_rate: 0.0001
  weight_decay: 0.000001
  decay_lr: 0.9
  decay_step: 1 # 몇 epoch이 지난후 decay_lr을 적용할지
context:
  using_cuda: True
validation:
  eval_period: 10
mlflow:
  using_mlflow: True
  run_name: classification




